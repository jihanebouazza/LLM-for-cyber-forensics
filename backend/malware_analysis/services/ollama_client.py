import json
import requests
from typing import List, Dict
import time
from ..utils.logging_utils import logger
from ..utils.ioc_validation import is_placeholder, valid_ip, valid_domain, valid_hash, looks_like_type_word, split_multi_values
import re
import uuid


OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL = "gemma2:2b"
ALLOWED_IOC_TYPES = {
    "url",
    "domain",
    "ip",
    "hash",
    "file_path",
    "registry_key",
    "mutex",
    "email",
    "process",
    "service",
    "user_agent",
}


def ollama_extract_from_text(report_text: str) -> dict:
    prompt = f"""
    You are a cyber malware analyst.
    Extract structured malware findings from the report text.

    Return ONLY valid JSON (no markdown, no explanation).
    Schema:
    {{
    "file_type": string|null,
    "detected_family": string|null,
    "risk_score": integer,
    "risk_level": "low"|"medium"|"high"|"critical",
    "behavior_summary": string,
    "behaviors": [string],
    "iocs": [{{"ioc_type": string, "value": string, "description": string|null, "source": "report"}}],
    "capabilities": [string],
    "config": {{"ransom_note_name": string|null, "encryption_extension": string|null, "target_folders": [string]|null}} | null,
    "recommended_actions": [string],
    "detection_hints": [{{"hint_type": string, "hint_text": string}}]
    }}

    Report text:
    {report_text}
    """.strip()

    r = requests.post(
        OLLAMA_URL,
        json={
            "model": MODEL,
            "prompt": prompt,
            "stream": False,
            "format": "json",
            "options": {"temperature": 0, "num_predict": 120},
            "keep_alive": "5m",
        },
        timeout=600,
    )
    data = r.json()
    raw = (data.get("response") or "").strip()
    return parse_json_loose(raw)


def chunk_text(text: str, size: int = 6000, overlap: int = 500) -> list[str]:
    chunks = []
    i = 0
    n = len(text)
    step = max(1, size - overlap)

    while i < n:
        chunks.append(text[i:i + size])
        i += step

    return chunks


def _call_ollama_json(prompt: str, timeout: int = 120, num_predict: int = 140) -> dict:
    payload = {
        "model": MODEL,
        "prompt": prompt,
        "stream": False,
        "format": "json",
        "options": {
            "temperature": 0,
            "num_predict": num_predict,
            "top_p": 1.0,
            "stop": ["\n\nChunk:"],
        },
        "keep_alive": "5m",
    }

    t0 = time.perf_counter()
    logger.info(
        f"[OLLAMA] POST start | timeout={timeout}s | prompt_chars={len(prompt)}")

    r = requests.post(OLLAMA_URL, json=payload, timeout=(10, timeout))

    t1 = time.perf_counter()
    logger.info(
        f"[OLLAMA] POST done | {t1 - t0:.2f}s | status={r.status_code}")

    # If Ollama returns non-JSON error page / text, this reveals it
    ct = r.headers.get("Content-Type", "")
    logger.info(f"[OLLAMA] content-type={ct!r} resp_chars={len(r.text)}")

    r.raise_for_status()

    try:
        data = r.json()
    except Exception:
        logger.exception(
            f"[OLLAMA] r.json() FAILED | body_start={r.text[:500]!r}")
        return {}

    raw = (data.get("response") or "").strip()
    logger.info(
        f"[OLLAMA] response_chars={len(raw)} response_start={raw[:300]!r}")

    out = parse_json_loose(raw)
    logger.info(f"[OLLAMA] parsed_keys={list(out.keys())[:20]} ok={bool(out)}")

    return out


def extract_iocs_chunked(report_text: str) -> List[Dict]:
    all_iocs: Dict[tuple, Dict] = {}
    chunks = chunk_text(report_text, size=3500, overlap=300)

    logger.info(f"[IOC] Total chars={len(report_text)} | chunks={len(chunks)}")

    for idx, chunk in enumerate(chunks, start=1):
        t0 = time.perf_counter()
        req_id = uuid.uuid4().hex[:8]

        logger.info(
            f"[IOC][{req_id}] Chunk {idx}/{len(chunks)} | chars={len(chunk)} | START")
        logger.info(
            f"[IOC] Chunk {idx}/{len(chunks)} preview: {chunk[:200]!r}")

        prompt = f"""
Return ONLY a JSON object with this shape:
{{"iocs": [{{"ioc_type": "<one of allowed>", "value": "<indicator>", "description": null}}]}}

Do NOT copy the example values. Use only indicators that appear in the chunk.

Allowed ioc_type values (one token only):
url|domain|ip|hash|file_path|registry_key|mutex|email|process|service|user_agent

Rules:
- ioc_type must be exactly one token from the allowed list
- value must be the indicator only (no "unknown", no "whitelisted", no extra words)
- DO NOT output placeholder values like "1.2.3.4", "example.com", "...", "null"
- Never return type-words as values: url, domain, ip, hash, file_path, registry_key, mutex, email, process, service, user_agent
- IMPORTANT: Do NOT return the allowed ioc_type list as values.
- Every item in "iocs" must be an object like {{"ioc_type":"ip","value":"8.8.8.8"}}.
- If you can’t find real indicators, return {{"iocs": []}}.
- Do NOT include the allowed ioc_type list in the output.
- Output must contain ONLY indicators found in the chunk (IPs/domains/URLs/hashes/paths/keys/etc).


Chunk:
{chunk}
""".strip()

        try:
            out = _call_ollama_json(prompt, timeout=300, num_predict=320) or {}
        except requests.exceptions.Timeout:
            logger.warning(
                f"[IOC] Chunk {idx}/{len(chunks)} | TIMEOUT | {time.perf_counter() - t0:.2f}s")
            continue
        except Exception as e:
            logger.exception(f"[IOC] Chunk {idx}/{len(chunks)} | ERROR | {e}")
            continue

        if isinstance(out, list):
            iocs_list = out
        else:
            iocs_list = (out or {}).get("iocs") or []
        logger.info(f"[IOC][{req_id}] raw_iocs_preview={iocs_list[:3]!r}")
        if not isinstance(iocs_list, list):
            logger.warning(f"[IOC][{req_id}] bad iocs type: {type(iocs_list)}")
            continue

        accepted = 0
        rejected = 0

        from collections import Counter
        reasons = Counter()

        for ioc in iocs_list:
            # ✅ STRING FALLBACK (some models ignore schema and output strings)
            if isinstance(ioc, str):
                rejected += 1
                reasons["string_ioc_not_allowed"] += 1
                continue

            # ✅ HARD GUARD
            if not isinstance(ioc, dict):
                rejected += 1
                continue

            # ✅ accept common alias keys from LLMs
            ioc_type = (
                ioc.get("ioc_type")
                or ioc.get("type")
                or ioc.get("indicator_type")
                or ioc.get("kind")
                or ""
            ).strip().lower()

            value = (
                ioc.get("value")
                or ioc.get("indicator")
                or ioc.get("ioc")
                or ""
            ).strip()

            # Basic sanity
            if not ioc_type or not value:
                reasons["missing_type_or_value"] += 1
                rejected += 1
                continue

            # Enforce allowed types
            if ioc_type not in ALLOWED_IOC_TYPES:
                reasons["type_not_allowed"] += 1
                rejected += 1
                continue

            # Drop sandbox self references + placeholders + type-word junk
            if is_placeholder(value):
                reasons["placeholder"] += 1
                rejected += 1
                continue

            if is_meta_reference(value):
                reasons["meta_reference_kept"] += 1
                # keep it but tag it
                ioc["description"] = (
                    ioc.get("description") or "") + " (sandbox reference)"
                # do NOT continue

            if looks_like_type_word(value):
                reasons["type_word_as_value"] += 1
                rejected += 1
                continue

            # Normalize + validate by type
            if ioc_type == "ip":
                value = value.split(":")[0].strip()
                if not valid_ip(value):
                    reasons["invalid_ip"] += 1
                    rejected += 1
                    continue

            elif ioc_type == "domain":
                if not valid_domain(value) or is_meta_reference(value):
                    reasons["invalid_domain"] += 1
                    rejected += 1
                    continue

            elif ioc_type == "hash":
                if not valid_hash(value):
                    reasons["invalid_hash"] += 1
                    rejected += 1
                    continue

            # (Optional) split comma-separated multi-values even in dict mode
            # e.g. "23.1.1.1, 23.1.1.2"
            vals = split_multi_values(value) if "," in value else [value]

            for v in vals:
                v = v.strip()
                if not v or is_placeholder(v) or is_meta_reference(v) or looks_like_type_word(v):
                    continue

                if ioc_type == "ip":
                    v = v.split(":")[0].strip()
                    if not valid_ip(v):
                        continue
                elif ioc_type == "domain":
                    if not valid_domain(v) or is_meta_reference(v):
                        continue
                elif ioc_type == "hash":
                    if not valid_hash(v):
                        continue

                key = (ioc_type, v.lower())
                all_iocs[key] = {
                    "ioc_type": ioc_type,
                    "value": v,
                    "description": ioc.get("description"),
                    "source": "report",
                }
                accepted += 1
        logger.info(
            f"[IOC][{req_id}] rejection_reasons_top={reasons.most_common(8)}")

        logger.info(
            f"[IOC] Chunk {idx}/{len(chunks)} accepted={accepted} rejected={rejected} | unique_so_far={len(all_iocs)}"
        )
        logger.info(
            f"[IOC] Chunk {idx}/{len(chunks)} | DONE | {time.perf_counter() - t0:.2f}s | iocs_in_chunk={len(iocs_list)}"
        )

    logger.info(f"[IOC] Merge complete | unique_iocs={len(all_iocs)}")
    return list(all_iocs.values())


def parse_json_loose(raw: str) -> dict:
    raw = (raw or "").strip()
    if raw in {"null", "None", ""}:
        return {}

    if raw.startswith("```"):
        logger.warning("[JSON] fenced output detected")
        raw = raw.strip("`").strip()
        if raw.lower().startswith("json"):
            raw = raw[4:].strip()

    try:
        obj = json.loads(raw)
        return obj if isinstance(obj, dict) else {}
    except Exception as e:
        logger.warning(f"[JSON] direct json.loads failed: {e}")

    start = raw.find("{")
    end = raw.rfind("}")
    if start != -1 and end != -1 and end > start:
        logger.warning("[JSON] attempting salvage parse using outer braces")
        try:
            obj = json.loads(raw[start:end + 1])
            return obj if isinstance(obj, dict) else {}
        except Exception as e:
            logger.warning(f"[JSON] salvage parse failed: {e}")
            return {}

    logger.warning("[JSON] no JSON object found at all")
    return {}


def is_meta_reference(value: str) -> bool:
    v = (value or "").lower()
    return any(x in v for x in [
        "any.run",
        "app.any.run",
        "any.run/report/",
        "any.run/tasks/",
    ])


def ollama_extract_behavior_block(report_text: str) -> dict:
    """
    Extract ONLY behavior_summary + behaviors.
    """
    logger.info(f"[LLM-BEHAV] START | chars={len(report_text)}")

    prompt = f"""
You are a malware analyst. Extract ONLY the following fields from the report text.
Return ONLY valid MINIFIED JSON in ONE LINE (no newlines, no indentation). No markdown.

Return exactly this schema:
{{
  "behavior_summary": string,
  "behaviors": [string]
}}

Rules:
- Use ONLY evidence from the text.
- If unknown: behavior_summary = "" and behaviors = []
- behaviors must be short action phrases (e.g., "creates scheduled task", "runs PowerShell").
- LIMITS: behavior_summary max 2 sentences. behaviors max 12 items.
- Output must be a single-line JSON object starting with {{ and ending with }}.

Report text:
{report_text}
""".strip()

    out = _call_ollama_json(prompt, timeout=240, num_predict=220) or {}
    if not out:
        logger.warning(
            "[LLM-BEHAV] empty/invalid JSON, retrying with higher num_predict")
        out = _call_ollama_json(prompt, timeout=240, num_predict=360) or {}

    logger.info(
        "[LLM-BEHAV] DONE | keys=%s behaviors=%d",
        list(out.keys())[:10],
        len(out.get("behaviors") or []) if isinstance(
            out.get("behaviors"), list) else -1,
    )
    return out


def ollama_extract_artifacts_block(report_text: str) -> dict:
    """
    Extract family/file type + capabilities/config/actions/hints.
    """
    logger.info(f"[LLM-ARTIF] START | chars={len(report_text)}")

    prompt = f"""
You are a malware analyst. Extract ONLY the following fields from the report text.
Return ONLY valid MINIFIED JSON in ONE LINE (no newlines, no indentation). No markdown.

Return exactly this schema:
{{
  "file_type": string|null,
  "detected_family": string|null,
  "capabilities": [string],
  "config": {{"ransom_note_name": string|null, "encryption_extension": string|null, "target_folders": [string]|null}} | null,
  "recommended_actions": [string],
  "detection_hints": [{{"hint_type": string, "hint_text": string}}]
}}

Rules:
- Use ONLY evidence from the text.
- If unknown, use null or [] (do NOT guess).
- LIMITS: capabilities max 10 items, recommended_actions max 6 items, detection_hints max 6 items.
- Output must be a single-line JSON object starting with {{ and ending with }}.


Report text:
{report_text}
""".strip()

    out = _call_ollama_json(prompt, timeout=300, num_predict=320) or {}
    if not out:
        logger.warning(
            "[LLM-ARTIF] empty/invalid JSON, retrying with higher num_predict")
        out = _call_ollama_json(prompt, timeout=300, num_predict=480) or {}

    logger.info(
        "[LLM-ARTIF] DONE | keys=%s caps=%d actions=%d hints=%d has_config=%s",
        list(out.keys())[:20],
        len(out.get("capabilities") or []) if isinstance(
            out.get("capabilities"), list) else -1,
        len(out.get("recommended_actions") or []) if isinstance(
            out.get("recommended_actions"), list) else -1,
        len(out.get("detection_hints") or []) if isinstance(
            out.get("detection_hints"), list) else -1,
        isinstance(out.get("config"), dict),
    )
    return out
